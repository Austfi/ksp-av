{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import s3fs\n",
    "import numcodecs as ncd\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Setup\n",
    "startdate = \"2023-10-01\"\n",
    "enddate = \"2023-10-02\"\n",
    "point_lat = 39.58148838130895\n",
    "point_lon = -105.94259648925797\n",
    "level = 'surface'\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "projection = ccrs.LambertConformal(central_longitude=262.5, central_latitude=38.5, \n",
    "                                   standard_parallels=(38.5, 38.5),\n",
    "                                   globe=ccrs.Globe(semimajor_axis=6371229, semiminor_axis=6371229))\n",
    "\n",
    "x, y = projection.transform_point(point_lon, point_lat, ccrs.PlateCarree())\n",
    "chunk_index = xr.open_zarr(s3fs.S3Map(\"s3://hrrrzarr/grid/HRRR_chunk_index.zarr\", s3=fs))\n",
    "nearest_point = chunk_index.sel(x=x, y=y, method=\"nearest\")\n",
    "\n",
    "# Data Retrieval Function\n",
    "def retrieve_data(s3_url, var):\n",
    "    with fs.open(s3_url, 'rb') as compressed_data:\n",
    "        buffer = ncd.blosc.decompress(compressed_data.read())\n",
    "        dtype = \"<f4\" if \"surface/PRES\" in s3_url else \"<f2\"\n",
    "        chunk = np.frombuffer(buffer, dtype=dtype)\n",
    "        data_array = np.reshape(chunk, (len(chunk)//(150*150), 150, 150))\n",
    "        return data_array\n",
    "\n",
    "# Data Collection\n",
    "data_collection = []\n",
    "variables = [\"SNOD\", \"GUST\", \"ASNOW_acc_fcst\", \"PRES\", \"TMP\"]\n",
    "\n",
    "for day in pd.date_range(start=startdate, end=enddate):\n",
    "    for hour in range(24):\n",
    "        date_str = day.strftime('%Y%m%d')\n",
    "        hour_str = f'{hour:02d}'\n",
    "        row = {'date': date_str, 'hour': hour_str}\n",
    "        for var in variables:\n",
    "            data_url = f'hrrrzarr/sfc/{date_str}/{date_str}_{hour_str}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "            fcst_chunk_id = f\"0.{nearest_point.chunk_id.values}\"\n",
    "            data = retrieve_data(data_url + fcst_chunk_id, var)\n",
    "            gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "            row[var] = gridpoint_forecast.mean()\n",
    "        data_collection.append(row)\n",
    "\n",
    "# Convert to DataFrame and Export to CSV\n",
    "df = pd.DataFrame(data_collection)\n",
    "df.to_csv('historical_hrrr_fcst.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
