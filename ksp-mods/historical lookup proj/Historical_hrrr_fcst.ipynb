{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Made To look up hrrr data\n",
    "Change startdate and enddate in lines 10 and 11\n",
    "currently only looks up surface: \"SNOD\", \"GUST\", \"ASNOW_acc_fcst\", \"PRES\", \"TMP\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1 \n",
    "raw data, needs converting\n",
    "output: historical_hrrr_fcst.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date hour      SNOD       GUST  ASNOW_acc_fcst          PRES     TMP\n",
      "0   20231001   00  0.000000  12.359375        0.000000  68498.125000  281.25\n",
      "1   20231001   01  0.000000  13.039062        0.000038  68506.664062  279.75\n",
      "2   20231001   02  0.000000  13.046875        0.000000  68497.781250  281.25\n",
      "3   20231001   03  0.000000  12.304688        0.000000  68506.664062  281.25\n",
      "4   20231001   04  0.000000  12.507812        0.000000  68508.890625  282.25\n",
      "5   20231001   05  0.000000  12.085938        0.000000  68499.445312  282.00\n",
      "6   20231001   06  0.000854  11.398438        0.000948  68454.789062  280.50\n",
      "7   20231001   07  0.000000  12.187500        0.000000  68507.218750  282.75\n",
      "8   20231001   08  0.000000  11.804688        0.000000  68496.664062  282.50\n",
      "9   20231001   09  0.000000  11.117188        0.000000  68523.890625  282.75\n",
      "10  20231001   10  0.000000  11.484375        0.000000  68519.445312  283.00\n",
      "11  20231001   11  0.000000  11.031250        0.000000  68505.554688  283.75\n",
      "12  20231001   12  0.000042  10.406250        0.001178  68401.460938  280.75\n",
      "13  20231001   13  0.000000  11.453125        0.000000  68507.218750  284.25\n",
      "14  20231001   14  0.000000  11.429688        0.000000  68511.664062  284.50\n",
      "15  20231001   15  0.000000  11.117188        0.000000  68514.445312  284.50\n",
      "16  20231001   16  0.000000  11.039062        0.000000  68515.000000  283.50\n",
      "17  20231001   17  0.000000  10.468750        0.000000  68514.445312  282.75\n",
      "18  20231001   18  0.000104   9.875000        0.000972  68324.789062  279.25\n",
      "19  20231001   19  0.000000  10.507812        0.000000  68527.781250  281.50\n",
      "20  20231001   20  0.000000  10.218750        0.000000  68521.664062  280.75\n",
      "21  20231001   21  0.000000  10.523438        0.000000  68525.554688  280.25\n",
      "22  20231001   22  0.000000  10.851562        0.000000  68525.000000  280.00\n",
      "23  20231001   23  0.000000  10.335938        0.000000  68548.890625  280.00\n",
      "24  20231002   00  0.000354   8.968750        0.001717  68323.960938  277.25\n",
      "25  20231002   01  0.000000  10.226562        0.000000  68536.664062  280.00\n",
      "26  20231002   02  0.000000  11.250000        0.000126  68536.109375  280.00\n",
      "27  20231002   03  0.000000  11.156250        0.000383  68522.781250  279.25\n",
      "28  20231002   04  0.000000  11.742188        0.000000  68486.664062  281.00\n",
      "29  20231002   05  0.000000  11.375000        0.000002  68462.218750  280.50\n",
      "30  20231002   06  0.000063   9.382812        0.000898  68284.164062  276.50\n",
      "31  20231002   07  0.000000  11.132812        0.000517  68438.890625  281.00\n",
      "32  20231002   08  0.000000  11.546875        0.000120  68421.664062  281.50\n",
      "33  20231002   09  0.000056  11.218750        0.000112  68378.890625  280.75\n",
      "34  20231002   10  0.000500  11.578125        0.001003  68350.554688  280.75\n",
      "35  20231002   11  0.000000  10.789062        0.000557  68335.000000  280.75\n",
      "36  20231002   12  0.000417   8.117188        0.009735  68263.750000  275.75\n",
      "37  20231002   13  0.001056   9.773438        0.006531  68298.890625  279.25\n",
      "38  20231002   14  0.006611   8.968750        0.013176  68273.335938  279.25\n",
      "39  20231002   15  0.001612   9.265625        0.007244  68256.109375  278.25\n",
      "40  20231002   16  0.008163   8.453125        0.015472  68211.664062  278.25\n",
      "41  20231002   17  0.007000   8.132812        0.010506  68190.554688  278.50\n",
      "42  20231002   18  0.003000   7.125000        0.014633  68276.664062  275.75\n",
      "43  20231002   19  0.014053   6.773438        0.020035  68110.554688  277.25\n",
      "44  20231002   20  0.014221   5.933594        0.024658  68122.218750  275.50\n",
      "45  20231002   21  0.005333   5.722656        0.011009  68133.890625  275.00\n",
      "46  20231002   22  0.005722   6.644531        0.010948  68124.445312  274.50\n",
      "47  20231002   23  0.003500   6.484375        0.009476  68115.554688  274.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import s3fs\n",
    "import numcodecs as ncd\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# define vars\n",
    "startdate = \"2023-10-01\"\n",
    "enddate = \"2023-10-02\"\n",
    "point_lat = 39.58148838130895\n",
    "point_lon = -105.94259648925797\n",
    "level = 'surface'\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "projection = ccrs.LambertConformal(central_longitude=262.5, central_latitude=38.5, \n",
    "                                   standard_parallels=(38.5, 38.5),\n",
    "                                   globe=ccrs.Globe(semimajor_axis=6371229, semiminor_axis=6371229))\n",
    "\n",
    "x, y = projection.transform_point(point_lon, point_lat, ccrs.PlateCarree())\n",
    "chunk_index = xr.open_zarr(s3fs.S3Map(\"s3://hrrrzarr/grid/HRRR_chunk_index.zarr\", s3=fs))\n",
    "nearest_point = chunk_index.sel(x=x, y=y, method=\"nearest\")\n",
    "\n",
    "# Data Retrieval Function\n",
    "def retrieve_data(s3_url, var):\n",
    "    with fs.open(s3_url, 'rb') as compressed_data:\n",
    "        buffer = ncd.blosc.decompress(compressed_data.read())\n",
    "        dtype = \"<f4\" if \"surface/PRES\" in s3_url else \"<f2\"\n",
    "        chunk = np.frombuffer(buffer, dtype=dtype)\n",
    "        data_array = np.reshape(chunk, (len(chunk)//(150*150), 150, 150))\n",
    "        return data_array\n",
    "\n",
    "# Data Collection\n",
    "data_collection = []\n",
    "variables = [\"SNOD\", \"GUST\", \"ASNOW_acc_fcst\", \"PRES\", \"TMP\"]\n",
    "\n",
    "for day in pd.date_range(start=startdate, end=enddate):\n",
    "    for hour in range(24):\n",
    "        date_str = day.strftime('%Y%m%d')\n",
    "        hour_str = f'{hour:02d}'\n",
    "        row = {'date': date_str, 'hour': hour_str}\n",
    "        for var in variables:\n",
    "            data_url = f'hrrrzarr/sfc/{date_str}/{date_str}_{hour_str}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "            fcst_chunk_id = f\"0.{nearest_point.chunk_id.values}\"\n",
    "            data = retrieve_data(data_url + fcst_chunk_id, var)\n",
    "            gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "            row[var] = gridpoint_forecast.mean()\n",
    "        data_collection.append(row)\n",
    "\n",
    "# Convert to DataFrame and Export to CSV\n",
    "df = pd.DataFrame(data_collection)\n",
    "df.to_csv('historical_hrrr_fcst.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2: \n",
    "Next version converts each variable based on maya's code conversions she used\n",
    "output: historical_hrrr_fcst_trnsfrm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date hour      SNOD      GUST  ASNOW_acc_fcst       PRES    TMP\n",
      "0   20231001   00  0.000000  27.68500        0.000000  20.229807  46.58\n",
      "1   20231001   01  0.000000  29.20750        0.001483  20.232328  43.88\n",
      "2   20231001   02  0.000000  29.22500        0.000000  20.229705  46.58\n",
      "3   20231001   03  0.000000  27.56250        0.000000  20.232328  46.58\n",
      "4   20231001   04  0.000000  28.01750        0.000000  20.232986  48.38\n",
      "5   20231001   05  0.000000  27.07250        0.000000  20.230196  47.93\n",
      "6   20231001   06  0.033641  25.53250        0.037321  20.217008  45.23\n",
      "7   20231001   07  0.000000  27.30000        0.000000  20.232492  49.28\n",
      "8   20231001   08  0.000000  26.44250        0.000000  20.229375  48.83\n",
      "9   20231001   09  0.000000  24.90250        0.000000  20.237416  49.28\n",
      "10  20231001   10  0.000000  25.72500        0.000000  20.236103  49.73\n",
      "11  20231001   11  0.000000  24.71000        0.000000  20.232001  51.08\n",
      "12  20231001   12  0.001640  23.31000        0.046370  20.201258  45.68\n",
      "13  20231001   13  0.000000  25.65500        0.000000  20.232492  51.98\n",
      "14  20231001   14  0.000000  25.60250        0.000000  20.233805  52.43\n",
      "15  20231001   15  0.000000  24.90250        0.000000  20.234626  52.43\n",
      "16  20231001   16  0.000000  24.72750        0.000000  20.234790  50.63\n",
      "17  20231001   17  0.000000  23.45000        0.000000  20.234626  49.28\n",
      "18  20231001   18  0.004102  22.12000        0.038260  20.178615  42.98\n",
      "19  20231001   19  0.000000  23.53750        0.000000  20.238565  47.03\n",
      "20  20231001   20  0.000000  22.89000        0.000000  20.236758  45.68\n",
      "21  20231001   21  0.000000  23.57250        0.000000  20.237907  44.78\n",
      "22  20231001   22  0.000000  24.30750        0.000000  20.237744  44.33\n",
      "23  20231001   23  0.000000  23.15250        0.000000  20.244799  44.33\n",
      "24  20231002   00  0.013948  20.09000        0.067583  20.178370  39.38\n",
      "25  20231002   01  0.000000  22.90750        0.000000  20.241188  44.33\n",
      "26  20231002   02  0.000000  25.20000        0.004956  20.241025  44.33\n",
      "27  20231002   03  0.000000  24.99000        0.015075  20.237088  42.98\n",
      "28  20231002   04  0.000000  26.30250        0.000000  20.226422  46.13\n",
      "29  20231002   05  0.000000  25.48000        0.000070  20.219202  45.23\n",
      "30  20231002   06  0.002462  21.01750        0.035350  20.166617  38.03\n",
      "31  20231002   07  0.000000  24.93750        0.020350  20.212313  46.13\n",
      "32  20231002   08  0.000000  25.86500        0.004724  20.207225  47.03\n",
      "33  20231002   09  0.002187  25.13000        0.004400  20.194593  45.68\n",
      "34  20231002   10  0.019693  25.93500        0.039499  20.186224  45.68\n",
      "35  20231002   11  0.000000  24.16750        0.021946  20.181630  45.68\n",
      "36  20231002   12  0.016408  18.18250        0.383271  20.160588  36.68\n",
      "37  20231002   13  0.041564  21.89250        0.257116  20.170966  42.98\n",
      "38  20231002   14  0.260270  20.09000        0.518738  20.163419  42.98\n",
      "39  20231002   15  0.063453  20.75500        0.285201  20.158331  41.18\n",
      "40  20231002   16  0.321395  18.93500        0.609149  20.145205  41.18\n",
      "41  20231002   17  0.275589  18.21750        0.413608  20.138971  41.63\n",
      "42  20231002   18  0.118120  15.96000        0.576108  20.164402  36.68\n",
      "43  20231002   19  0.553280  15.17250        0.788770  20.115344  39.38\n",
      "44  20231002   20  0.559888  13.29125        0.970793  20.118789  36.23\n",
      "45  20231002   21  0.209958  12.81875        0.433433  20.122236  35.33\n",
      "46  20231002   22  0.225277  14.88375        0.431030  20.119446  34.43\n",
      "47  20231002   23  0.137794  14.52500        0.373059  20.116821  33.53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import s3fs\n",
    "import numcodecs as ncd\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# define vars\n",
    "startdate = \"2023-10-01\"\n",
    "enddate = \"2023-10-02\"\n",
    "point_lat = 39.58148838130895\n",
    "point_lon = -105.94259648925797\n",
    "level = 'surface'\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "projection = ccrs.LambertConformal(central_longitude=262.5, central_latitude=38.5, \n",
    "                                   standard_parallels=(38.5, 38.5),\n",
    "                                   globe=ccrs.Globe(semimajor_axis=6371229, semiminor_axis=6371229))\n",
    "\n",
    "x, y = projection.transform_point(point_lon, point_lat, ccrs.PlateCarree())\n",
    "chunk_index = xr.open_zarr(s3fs.S3Map(\"s3://hrrrzarr/grid/HRRR_chunk_index.zarr\", s3=fs))\n",
    "nearest_point = chunk_index.sel(x=x, y=y, method=\"nearest\")\n",
    "\n",
    "# Data Retrieval Function\n",
    "def retrieve_data(s3_url, var):\n",
    "    with fs.open(s3_url, 'rb') as compressed_data:\n",
    "        buffer = ncd.blosc.decompress(compressed_data.read())\n",
    "        dtype = \"<f4\" if \"surface/PRES\" in s3_url else \"<f2\"\n",
    "        chunk = np.frombuffer(buffer, dtype=dtype)\n",
    "        data_array = np.reshape(chunk, (len(chunk)//(150*150), 150, 150))\n",
    "        return data_array\n",
    "\n",
    "# Data Collection\n",
    "data_collection = []\n",
    "variables = [\"SNOD\", \"GUST\", \"ASNOW_acc_fcst\", \"PRES\", \"TMP\"]\n",
    "\n",
    "for day in pd.date_range(start=startdate, end=enddate):\n",
    "    for hour in range(24):\n",
    "        date_str = day.strftime('%Y%m%d')\n",
    "        hour_str = f'{hour:02d}'\n",
    "        row = {'date': date_str, 'hour': hour_str}\n",
    "        for var in variables:\n",
    "            data_url = f'hrrrzarr/sfc/{date_str}/{date_str}_{hour_str}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "            fcst_chunk_id = f\"0.{nearest_point.chunk_id.values}\"\n",
    "            data = retrieve_data(data_url + fcst_chunk_id, var)\n",
    "            gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "            mean_value = gridpoint_forecast.mean()\n",
    "\n",
    "            # Apply specific transformations for each variable\n",
    "            if var == \"PRES\":\n",
    "                row[var] = mean_value / 3386\n",
    "            elif var == \"SNOD\" or var == \"ASNOW_acc_fcst\":\n",
    "                row[var] = mean_value * 39.37\n",
    "            elif var == \"GUST\":\n",
    "                row[var] = mean_value * 2.24\n",
    "            elif var == \"TMP\":\n",
    "                row[var] = (mean_value - 273.15) * (9/5) + 32\n",
    "            else:\n",
    "                row[var] = mean_value\n",
    "\n",
    "        data_collection.append(row)\n",
    "\n",
    "# Convert to DataFrame and Export to CSV\n",
    "df = pd.DataFrame(data_collection)\n",
    "df.to_csv('historical_hrrr_fcst_trnsfrm.csv', index=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V3:\n",
    "cleaning up by taking output and rounds to the hundredth \n",
    "output: historical_hrrr_fcst_trnsfrm_rnd.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date hour  SNOD   GUST  ASNOW_acc_fcst   PRES    TMP\n",
      "0   20231001   00   0.0  27.68            0.00  20.23  46.58\n",
      "1   20231001   01   0.0  29.21            0.00  20.23  43.88\n",
      "2   20231001   02   0.0  29.22            0.00  20.23  46.58\n",
      "3   20231001   03   0.0  27.56            0.00  20.23  46.58\n",
      "4   20231001   04   0.0  28.02            0.00  20.23  48.38\n",
      "..       ...  ...   ...    ...             ...    ...    ...\n",
      "67  20231003   19   0.0  12.85            0.00  20.19  32.63\n",
      "68  20231003   20   0.0  11.69            0.00  20.20  30.83\n",
      "69  20231003   21   0.0  11.37            0.01  20.20  32.18\n",
      "70  20231003   22   0.0   9.99            0.00  20.21  32.18\n",
      "71  20231003   23   0.0   9.19            0.00  20.21  32.18\n",
      "\n",
      "[72 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import s3fs\n",
    "import numcodecs as ncd\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# define vars\n",
    "startdate = \"2023-10-01\"\n",
    "enddate = \"2023-10-03\"\n",
    "point_lat = 39.58148838130895\n",
    "point_lon = -105.94259648925797\n",
    "level = 'surface'\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "projection = ccrs.LambertConformal(central_longitude=262.5, central_latitude=38.5, \n",
    "                                   standard_parallels=(38.5, 38.5),\n",
    "                                   globe=ccrs.Globe(semimajor_axis=6371229, semiminor_axis=6371229))\n",
    "\n",
    "x, y = projection.transform_point(point_lon, point_lat, ccrs.PlateCarree())\n",
    "chunk_index = xr.open_zarr(s3fs.S3Map(\"s3://hrrrzarr/grid/HRRR_chunk_index.zarr\", s3=fs))\n",
    "nearest_point = chunk_index.sel(x=x, y=y, method=\"nearest\")\n",
    "\n",
    "# Data Retrieval Function\n",
    "def retrieve_data(s3_url, var):\n",
    "    with fs.open(s3_url, 'rb') as compressed_data:\n",
    "        buffer = ncd.blosc.decompress(compressed_data.read())\n",
    "        dtype = \"<f4\" if \"surface/PRES\" in s3_url else \"<f2\"\n",
    "        chunk = np.frombuffer(buffer, dtype=dtype)\n",
    "        data_array = np.reshape(chunk, (len(chunk)//(150*150), 150, 150))\n",
    "        return data_array\n",
    "\n",
    "# Data Collection\n",
    "data_collection = []\n",
    "variables = [\"SNOD\", \"GUST\", \"ASNOW_acc_fcst\", \"PRES\", \"TMP\"]\n",
    "\n",
    "for day in pd.date_range(start=startdate, end=enddate):\n",
    "    for hour in range(24):\n",
    "        date_str = day.strftime('%Y%m%d')\n",
    "        hour_str = f'{hour:02d}'\n",
    "        row = {'date': date_str, 'hour': hour_str}\n",
    "        for var in variables:\n",
    "            data_url = f'hrrrzarr/sfc/{date_str}/{date_str}_{hour_str}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "            fcst_chunk_id = f\"0.{nearest_point.chunk_id.values}\"\n",
    "            data = retrieve_data(data_url + fcst_chunk_id, var)\n",
    "            gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "            mean_value = gridpoint_forecast.mean()\n",
    "\n",
    "            # Apply specific transformations for each variable and round to two decimal places\n",
    "            if var == \"PRES\":\n",
    "                row[var] = round(mean_value / 3386, 2)\n",
    "            elif var == \"SNOD\" or var == \"ASNOW_acc_fcst\":\n",
    "                row[var] = round(mean_value * 39.37, 2)\n",
    "            elif var == \"GUST\":\n",
    "                row[var] = round(mean_value * 2.24, 2)\n",
    "            elif var == \"TMP\":\n",
    "                row[var] = round((mean_value - 273.15) * (9/5) + 32, 2)\n",
    "            else:\n",
    "                row[var] = round(mean_value, 2)\n",
    "\n",
    "        data_collection.append(row)\n",
    "\n",
    "# Convert to DataFrame and Export to CSV\n",
    "df = pd.DataFrame(data_collection)\n",
    "df.to_csv('historical_hrrr_fcst_trnsfrm_rnd.csv', index=False)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to-do: figure out what is most relevant to compare, forecast vs annalyzed or hrrr forecast vs weather station data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
